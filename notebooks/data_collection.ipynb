{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/saschalandegge/opt/anaconda3/envs/main/lib/python3.7/site-packages (2.23.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/saschalandegge/opt/anaconda3/envs/main/lib/python3.7/site-packages (from requests) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/saschalandegge/opt/anaconda3/envs/main/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/saschalandegge/opt/anaconda3/envs/main/lib/python3.7/site-packages (from requests) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saschalandegge/opt/anaconda3/envs/main/lib/python3.7/site-packages (from requests) (2020.4.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"AIzaSyDlrOVHZ8stkQCS52a1qf2f06zrvwnVPGw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://youtube.googleapis.com/youtube/v3/\"\n",
    "headers = {'Accept': 'application/json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_from_file(directory, filename):\n",
    "    with open(os.path.join(directory, filename)) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_to_file(directory, data, filename=None):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    if (filename is None):\n",
    "        filename = '{0}.json'.format(time.time())\n",
    "\n",
    "    with open(os.path.join(directory, filename), 'w') as f:\n",
    "        json.dump(data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_video_ids_to_url_file(directory, video_ids):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    filename = '{0}.csv'.format(time.time())\n",
    "    \n",
    "    file_path = os.path.join(directory, filename)\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        for item in video_ids:\n",
    "            f.write(\"http://www.youtube.com/watch?v={0}\".format(item))\n",
    "            f.write(\"\\r\\n\")\n",
    "            \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(keyword, next_page_token):\n",
    "    part = \"snippet\"\n",
    "    max_results = 50\n",
    "    res_type = \"video\"\n",
    "    \n",
    "    url = '{0}search?part={1}&maxResults={2}&type={3}&q={4}&key={5}'.format(\n",
    "        base_url, \n",
    "        part,\n",
    "        max_results, \n",
    "        res_type,\n",
    "        keyword, \n",
    "        API_KEY\n",
    "    )\n",
    "    \n",
    "    if (next_page_token is not None):\n",
    "        url += '&pageToken={0}'.format(next_page_token)\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.content.decode('utf-8'))\n",
    "    else:\n",
    "        print(\"HTTP not OK: {0}\".format(response.content))\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_ids(search_data):\n",
    "    \n",
    "#     Initialize list\n",
    "    video_ids = set()\n",
    "\n",
    "#     Parse JSON\n",
    "    for search_result in search_data[\"items\"]:\n",
    "        video_ids.add(search_result[\"id\"][\"videoId\"]);\n",
    "\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(video_ids):\n",
    "    \n",
    "    csv_video_ids = \",\".join(video_ids);\n",
    "    \n",
    "    part = \"snippet,contentDetails\"\n",
    "    url = \"{0}videos?part={1}&id={2}&key={3}\".format(\n",
    "        base_url,\n",
    "        part,\n",
    "        csv_video_ids,\n",
    "        API_KEY\n",
    "    )\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.content.decode('utf-8'))[\"items\"]\n",
    "    else:\n",
    "        print(\"HTTP not OK: {0}\".format(response.content))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def youtube_downloader(url_file_path):\n",
    "    # Invoke external YouTube downloader with YouTube URL file\n",
    "    bashCommand = \"youtube-dl -a {0} -j > output_video_traces.temp\".format(url_file_path)\n",
    "\n",
    "    print(\"Running youtube-dl: {0}\".format(bashCommand))\n",
    "\n",
    "    !{bashCommand}\n",
    "    \n",
    "    # Open output_video_details file and make a proper array out of it\n",
    "    with open(\"output_video_traces.temp\") as temp_file:\n",
    "        json_strings = temp_file.readlines()\n",
    "\n",
    "        json_array = []\n",
    "\n",
    "        for json_str in json_strings:\n",
    "            json_array.append(json.loads(json_str))\n",
    "\n",
    "        # Save json array to disk\n",
    "        write_json_to_file(\"traces\", json_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def do_work(search_term, page_limit):\n",
    "    \n",
    "    # Keep track of what (unique) video IDs we have found\n",
    "    video_ids_set = set(read_json_from_file(\"cache\", \"found_video_ids.json\"))\n",
    "    # Count previously found videos\n",
    "    initial_video_ids_set_size = len(video_ids_set)\n",
    "    \n",
    "    next_page_token = None\n",
    "    \n",
    "    for i in range(page_limit):\n",
    "        \n",
    "        # Search YouTube API\n",
    "        search_result = search(search_term, next_page_token)\n",
    "        # Save search result\n",
    "        write_json_to_file(\"searches\", search_result)\n",
    "        \n",
    "        # Parse search result to get video ids\n",
    "        found_video_ids = get_video_ids(search_result)\n",
    "        \n",
    "        # Find which found IDs are not duplicates\n",
    "        unique_video_ids = found_video_ids.difference(video_ids_set)\n",
    "        \n",
    "        # Obtain video details (including projection method)\n",
    "        video_details = get_video_details(unique_video_ids)\n",
    "        # Save video details\n",
    "        #write_json_to_file(\"video_details\", list(unique_video_ids))\n",
    "        \n",
    "        # Find which of our video IDs refer to 360 videos\n",
    "        for video_details_item in video_details:\n",
    "            if (video_details_item['contentDetails']['projection'] != \"360\"):\n",
    "                # This is not a 360 video; remove it from the set\n",
    "                unique_video_ids.remove(video_details_item['id'])\n",
    "        \n",
    "        # We now have a local set (unique_video_ids) which contains unique 360 video IDs\n",
    "        \n",
    "        # Check if our set is not empty\n",
    "        if (len(unique_video_ids) != 0):\n",
    "            # Save video IDs as URLs to hand to external YouTube Downloader\n",
    "            url_file_path = write_video_ids_to_url_file(\"videos\", unique_video_ids)\n",
    "\n",
    "            # Add found video IDs to our set (no duplicates)\n",
    "            video_ids_set.update(unique_video_ids)\n",
    "\n",
    "            # Download video traces for the URLs found\n",
    "            youtube_downloader(url_file_path)\n",
    "        \n",
    "            print(\"Processed {0} out of {1} search pages. Found and stored {2} video traces so far.\".format(\n",
    "                i + 1,\n",
    "                page_limit,\n",
    "                len(video_ids_set) - initial_video_ids_set_size))\n",
    "        \n",
    "        # Check if there is a next page available\n",
    "        if ('nextPageToken' in search_result):\n",
    "            # Update next_page_token for subsequent searches\n",
    "            next_page_token = search_result['nextPageToken']\n",
    "        elif (i < page_limit - 1):\n",
    "            # There are no more search results for us after this\n",
    "            print(\"No more search results to explore for this search term: \\\"{0}\\\". Exiting...\".format(search_term))\n",
    "            break\n",
    "        \n",
    "    print(\"Done. Processed and stored a total of {0} new 360-degree video traces. (Total cached: {1})\".format(\n",
    "        len(video_ids_set) - initial_video_ids_set_size,\n",
    "         len(video_ids_set)))\n",
    "    \n",
    "    return video_ids_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running youtube-dl: youtube-dl -a videos/1607429747.592078.csv -j > output_video_traces.temp\n",
      "Processed 3 out of 1000 search pages. Found and stored 5 video traces so far.\n",
      "Running youtube-dl: youtube-dl -a videos/1607429753.5197492.csv -j > output_video_traces.temp\n",
      "Processed 4 out of 1000 search pages. Found and stored 7 video traces so far.\n",
      "Running youtube-dl: youtube-dl -a videos/1607429757.93767.csv -j > output_video_traces.temp\n",
      "Processed 5 out of 1000 search pages. Found and stored 10 video traces so far.\n",
      "Running youtube-dl: youtube-dl -a videos/1607429762.793486.csv -j > output_video_traces.temp\n",
      "Processed 6 out of 1000 search pages. Found and stored 12 video traces so far.\n",
      "Running youtube-dl: youtube-dl -a videos/1607429769.434012.csv -j > output_video_traces.temp\n",
      "Processed 8 out of 1000 search pages. Found and stored 15 video traces so far.\n",
      "Running youtube-dl: youtube-dl -a videos/1607429774.36975.csv -j > output_video_traces.temp\n",
      "Processed 9 out of 1000 search pages. Found and stored 19 video traces so far.\n",
      "Running youtube-dl: youtube-dl -a videos/1607429780.222069.csv -j > output_video_traces.temp\n",
      "Processed 10 out of 1000 search pages. Found and stored 26 video traces so far.\n",
      "Running youtube-dl: youtube-dl -a videos/1607429787.033859.csv -j > output_video_traces.temp\n",
      "Processed 11 out of 1000 search pages. Found and stored 30 video traces so far.\n",
      "Running youtube-dl: youtube-dl -a videos/1607429792.58175.csv -j > output_video_traces.temp\n",
      "Processed 12 out of 1000 search pages. Found and stored 31 video traces so far.\n",
      "HTTP not OK: b'{\\n  \"error\": {\\n    \"code\": 403,\\n    \"message\": \"The request cannot be completed because you have exceeded your \\\\u003ca href=\\\\\"/youtube/v3/getting-started#quota\\\\\"\\\\u003equota\\\\u003c/a\\\\u003e.\",\\n    \"errors\": [\\n      {\\n        \"message\": \"The request cannot be completed because you have exceeded your \\\\u003ca href=\\\\\"/youtube/v3/getting-started#quota\\\\\"\\\\u003equota\\\\u003c/a\\\\u003e.\",\\n        \"domain\": \"youtube.quota\",\\n        \"reason\": \"quotaExceeded\"\\n      }\\n    ]\\n  }\\n}\\n'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-42715d47b303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessed_video_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_work\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"360 sports\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-eb04c2582929>\u001b[0m in \u001b[0;36mdo_work\u001b[0;34m(search_term, page_limit)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Find which of our video IDs refer to 360 videos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mvideo_details_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideo_details\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvideo_details_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contentDetails'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'projection'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"360\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# This is not a 360 video; remove it from the set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "processed_video_ids = do_work(\"360 sports\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store video IDs so that subsequent runs will avoid duplicates\n",
    "write_json_to_file(\"cache\", list(processed_video_ids), \"found_video_ids.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
